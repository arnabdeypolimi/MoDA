[project]
name = "moda"
version = "0.1.0"
description = "MoDA: Multi-modal Diffusion Architecture for Talking Head Generation"
readme = "README.md"
requires-python = ">=3.10,<3.11"
dependencies = [
    "accelerate==0.28.0",
    "albumentations==1.4.10",
    "audio-separator==0.17.2",
    "av==12.1.0",
    "bitsandbytes==0.43.1",
    "decord==0.6.0",
    "diffusers==0.30.0",
    "einops==0.8.0",
    "ffmpeg-python==0.2.0",
    "gradio==6.3.0",
    "huggingface==0.0.1",
    "huggingface-hub==0.36.0",
    "imageio==2.34.2",
    "imageio-ffmpeg==0.5.1",
    "insightface==0.7.3",
    "isort==5.13.2",
    "librosa==0.10.2.post1",
    "lmdb==1.4.1",
    "matplotlib==3.9.0",
    "mediapipe==0.10.14",
    "mlflow==2.13.1",
    "moviepy==1.0.3",
    "numpy==1.26.4",
    "omegaconf==2.3.0",
    "onnx==1.16.1",
    "onnx2torch==1.5.14",
    "onnxruntime-gpu==1.19.2",
    "opencv-python==4.10.0.84",
    "pillow==10.3.0",
    "pre-commit==3.7.1",
    "pydub==0.25.1",
    "pykalman==0.9.7",
    "pyyaml==6.0.1",
    "rich==13.7.1",
    "scikit-image==0.24.0",
    "scipy==1.13.1",
    "tensorboardX==2.6.2.2",
    "torch==2.6.0",
    "torchaudio==2.6.0",
    "torchvision==0.21.0",
    "transformers==4.57.5",
    "tyro==0.8.5",
    "xformers==0.0.29.post3",
]

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.hatch.build.targets.wheel]
packages = ["src"]

# Limit resolution to Linux only (CUDA/GPU support)
[tool.uv]
environments = ["sys_platform == 'linux'"]

[tool.uv.sources]
torch = { index = "pytorch-cu124" }
torchvision = { index = "pytorch-cu124" }
torchaudio = { index = "pytorch-cu124" }
xformers = { index = "pytorch-cu124" }
onnxruntime-gpu = { index = "onnxruntime-cuda12" }

[[tool.uv.index]]
name = "pytorch-cu124"
url = "https://download.pytorch.org/whl/cu124"
explicit = true

[[tool.uv.index]]
name = "onnxruntime-cuda12"
url = "https://aiinfra.pkgs.visualstudio.com/PublicPackages/_packaging/onnxruntime-cuda-12/pypi/simple/"
explicit = true
